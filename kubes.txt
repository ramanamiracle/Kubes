################################   kubectl basic commands  #######################################

kubectl version
kubectl version --short
kubectl cluster-info

kubectl get nodes -o wide
kubectl get events  
kubectl cordon worker2.example.com
#worker2.example.com   Ready,SchedulingDisabled
kubectl uncordon worker2.example.com

kubectl drain worker2.example.com
#worker2.example.com   Ready,SchedulingDisabled
#pod/ngnix-595c5d5495-l628h evicted
kubectl uncordon worker2.example.com

kubectl api-resources
kubectl api-resources -o wide
kubectl api-resources --namespaced=true

kubectl api-versions
kubectl get apiservice

kubectl get componentstatus
kubectl get cs
kubectl explain deployment.spec

kubectl config view
kubectl config current-context
kubectl config get-contexts
kubectl config use-context develop

kubectl auth can-i list deployment --as=tiller
kubectl auth can-i list deployment
kubectl auth can-i list deployment
kubectl auth can-i list deployment --as=kubernetes-admin

kubectl get ns
kubectl get namespaces
kubectl get all -n kube-system

kubectl get quota -n default
kubectl get limitrange -n default 

kubectl proxy --port 8080
kubectl proxy --address 0.0.0.0 --accept-hosts '.*'

kubectl get all -n kube-system -o wide

kubectl get --raw '/apis/'
kubectl get --raw '/apis/metrics.k8s.io/'
kubectl get pods --v=9
kubectl get pods --v=6


################################   kubectl run pod/job/cronjob  ##########################

## kubectl running pod ##

# Restart Policies --> Never | Always | OnFailure

# client side dry run & server side dry run
kubectl run sample --restart=Never --image=busybox --dry-run -o yaml > pod.yaml
kubectl run sample --restart=Never --image=busybox --server-dry-run -o yaml > pod.yaml
kubectl diff -f pod.yaml

kubectl run --generator="run-pod/v1" nginx --image=nginx
kubectl run nginx --restart=Never --image=nginx
kubectl run --restart=Never -it busybox --image=busybox -- sh
kubectl exec busybox -c busybox -- ls /

kubectl label pods nginx env=develop
kubectl annotate pods nginx email=some@some.com

kubectl port-forward --address 0.0.0.0 pod/nginx 8000:80

kubectl logs -l run=nginx 
kubectl logs nginx-6db489d4b7-x5k9n --previous
kubectl logs ngnix-595c5d5495-76rmc -c ngnix

kubectl get pods -o wide --show-labels -l env=dev,run=nginx

## kubectl running job ##
kubectl run nginx --restart=OnFailure --image=busybox -- sleep 100
kubectl exec -it nginx-9fs84 sh
kubectl get jobs
kubectl describe job nginx
kubectl describe pod nginx-9fs84

# job yaml file
kubectl create -f countdown-jobs.yaml
kubectl get jobs
kubectl get po
kubectl describe jobs countdown

## kubectl running cronjob ##
kubectl run cj --schedule="*/5 * * * *" --restart=OnFailure --image=busybox -- /bin/sh -c "date; echo 'ended'"
kubectl run --generator=run-pod/v1 hello --schedule="*/1 * * * *" --restart=OnFailure --image=busybox -- /bin/sh -c "date; echo Hello from the Kubernetes cluster"

kubectl get jobs --watch
kubectl logs pod/cj-1577162160-qqg2w
kubectl delete cronjob.batch/cj

# cronjob yaml file
kubectl create -f cronjob.yaml
kubectl get cronjobs
kubectl get jobs
kubectl get po
kubectl describe jobs sample-cron

## node labels
kubectl label node kmaster fast=true

## node taint
kubectl taint node kmaster key=value:taint-effect
# taint-effect --> NoSchedule | PreferNoSchedule | NoExecute

kubectl taint node kmaster app=blue:NoSchedule

## Readiness & Liveliness probes
# Probe handlers --> http , tcp or arbitrary exec

################################   kubectl configmaps & secrets   ##########################

## config map from files
echo -n 'env=prod' > env.txt
echo -n 'count=2' > count.txt

kubectl create configmap some-config --from-file=env.txt --from-file=count.txt

kubectl get configmaps
kubectl describe configmaps some-config

kubectl create -f nginx-pod-configmap-vol.yaml
kubectl exec nginx-pod-configmap-vol ls /etc/data

## config map from literal values
kubectl create configmap redis-configmap-env --from-literal=key1=value1 --from-literal=key2=value2

kubectl create -f redis-pod-configmap-env.yaml
kubectl exec redis-pod-configmap-env env | grep key

## creating secrets from kubectl

kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root

echo -n 'admin' > username.txt
echo -n 'pa$$w00rd' > password.txt

kubectl create secret generic nginx-secret-vol --from-file=username.txt --from-file=password.txt
kubectl get secrets
kubectl describe secrets nginx-secret-vol

kubectl create -f nginx-pod-secret-vol.yaml
kubectl exec nginx-pod-secret-vol ls /app/cred

## creating secrets from yaml file
echo -n 'admin' | base64
echo -n 'pa$$w00rd' | base64

kubectl create -f redis-secret-env.yaml
kubectl get secret
kubectl describe secret redis-secret-env

kubectl create -f redis-pod-secret-env.yaml
kubectl exec redis-pod-secret-env env | grep SECRET


################################   kubectl replicaset & deployments   ##########################

## Replication Controller ##
kubectl create -f nginx-rc.yaml
kubectl get po -o wide --watch
kubectl get po -l app=nginx-app
kubectl get rc nginx-rc
kubectl describe rc nginx-rc

kubectl scale rc nginx-rc --replicas=5
kubectl delete -f nginx-rc.yaml

## ReplicaSet ##

kubectl create -f nginx-rs.yaml
kubectl get po -o wide
kubectl get po -l app=nginx-app
kubectl get rs nginx-rs -o wide
kubectl describe rs nginx-rs

kubectl scale rs nginx-rs --replicas=5
kubectl delete -f nginx-rs.yaml


## Deployment ##

kubectl run nginx --image=nginx
kubectl create deployment nginx --image=nginx
kubectl get pods -o wide --show-labels
kubectl get deployments -o wide
kubectl get rs -o wide

kubectl describe rs nginx-6db489d4b7

kubectl scale --replicas=3 deploy/nginx

kubectl autoscale deployment nginx --min=2 --max=10
#horizontalpodautoscaler.autoscaling/nginx autoscaled

kubectl set image deploy/nginx nginx=nginx:1.17.6
kubectl rollout status deploy/nginx
kubectl rollout history deploy/ngin
kubectl rollout undo deploy/nginx
kubectl rollout undo deploy/nginx --to-revision=1

# deployment yaml file
kubectl create -f nginx-deploy.yaml 
kubectl get deploy -l app=nginx-app
kubectl get rs -l app=nginx-app
kubectl get po -l app=nginx-app
kubectl describe deploy nginx-deploy

kubectl set image deploy nginx-deploy nginx-container=nginx:1.91 --record
kubectl rollout status deployment/nginx-deploy
kubectl rollout history deployment/nginx-deploy
kubectl rollout history deploy nginx-deploy --revision=4
kubectl rollout undo deployment/nginx-deploy
kubectl rollout status deployment/nginx-deploy
kubectl describe deploy nginx-deploy | grep -i image

kubectl scale deployment nginx-deploy --replicas=5


################################   DaemonSet & Statefulset  ##########################

## DaemonSet
kubectl create -f fluentd-ds-allnodes.yaml
kubectl get po -o wide
kubectl get ds
kubectl describe ds fluentd-ds

kubectl get nodes
kubectl label nodes worker1 worker2 disktype=ssd
kubectl get nodes --show-labels

kubectl create -f nginx-ds-subsetnodesss.yaml
kubectl get po -o wide
kubectl get ds
kubectl describe ds nginx-ds

## Statefulset


################################  Services (ClusterIp, NodePort, LoadBalancer)   ##########################

kubectl get svc

kubectl expose pod httpd --name=nginx-svc --type=NodePort --port=80
kubectl expose rc nginx --port=80 --target-port=8000
kubectl delete svc nginx-svc

kubectl expose deploy nginx-deploy --name=nginx-svc --type=LoadBalancer --port=80 --target-port=80
kubectl expose deploy nginx-deploy --name=nginx-svc --type=ClusterIp --port=80 --target-port=80
kubectl expose deploy nginx-deploy --name=nginx-svc --type=NodePort --port=80


## ClusterIp
# yaml file
kubectl create -f nginx-deploy.yaml
kubectl create -f nginx-svc-cip.yaml
kubectl get pod -l app=nginx-app
kubectl get deploy -l app=nginx-app 
kubectl get service -l app=nginx-app
kubectl describe service my-service

# from swith in cluster
curl http://clusterip:port


## NodePort
# yaml file
kubectl create -f nginx-deploy.yaml
kubectl create -f nginx-svc.yaml
kubectl get service -l app=nginx-app
kubectl get svc -l app=nginx-app
kubectl get po -o wide
kubectl describe svc my-service

curl http://[POD-IP]

#from external
http://nodep-ip:nodePort


## LoadBalancer

kubectl create -f nginx-deploy.yaml
kubectl create -f nginx-svc-lb.yaml
kubectl get pod -l app=nginx-app
kubectl get deploy -l app=nginx-app 
kubectl get service -l app=nginx-app
kubectl describe service my-service

# Using load-balancer-ip
http://load-balancer-ip

# Using nodePorts
http://nodeip:nodeport



################################  Storage, PV & PVC  ##########################

## emptyDir
kubectl create -f nginx-emptydir.yaml
kubectl get po -o wide
kubectl exec nginx-emptydir df /test-mnt
kubectl describe pod nginx-emptydir

## hostPath
kubectl create -f nginx-hostpath.yaml
kubectl get po
kubectl exec nginx-hostpath df /test-mnt

kubectl delete po nginx-hostpath
kubectl get po
ls /test-vol

# ReclaimPolicy (persistentVolumeReclaimPolicy) --> Retain | Recycle | delete
# Access Mode (accessModes) --> RWO | RWM | ROM

## nfs
kubectl create -f pv-nfs.yaml
kubectl create -f pvc-nfs.yaml

kubectl get pv,pvc

kubectl create -f nfs-nginx.yaml


################################# Metric server ########################################

helm inspect values stable/metrics-server > metrics-server.values
helm show values stable/metrics-server > metrics-server.values

# edit metrics-server.values
hostNetwork:
  enabled: true

args:
 - --kubelet-insecure-tls

helm install metrics-server stable/metrics-server --namespace kube-system --values metrics-server.values

kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes"
kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/<NODE_NAME> | jq
kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/<NAMESPACE>/pods/<POD_NAME> | jq

kubectl top nodes
kubectl top pods

kubectl api-resources
nodes                                          metrics.k8s.io                 false        NodeMetrics
pods                                           metrics.k8s.io                 true         PodMetrics

kubectl get apiservices
v1beta1.metrics.k8s.io                 kube-system/metrics-server   True        9m5s

################################# Ingress nginx #########################################

helm install ingress-nginx stable/nginx-ingress --set rbac.create=true
kubectl get all -o wide


################################# Metal LB #############################################

kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.3/manifests/metallb.yaml
kubectl apply -f layer2-cm.yaml

kubectl get all -n metallb-system -o wide


################################## RBAC ##################################################

----------------------
### Rules:
apiGroups:
  - "" [= core apigroup]
  - extensions
  - apps 
  - networking
  - etc.,
resources:
  - pods
  - deployments
  - replicaset
  - etc.,
verbs:
  - get, list
  - watch, updated
  - delete
  - etc.,
-------------------------

kubectl create ns sample

## create user private key
openssl genrsa -out john.key 2048  # john.key

## create certificate signing request
openssl req -new -key john.key -out john.csr -subj "/CN=john/O=sample" # john.csr

## Sign csr using CA 
#/etc/kubernets/pki --> ca.crt and ca.key
sudo openssl x509 -req -in john.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out john.crt -days 365

## create kubeconfig 
# set cluster
kubectl --kubeconfig john.kubeconfig config set-cluster kubernetes --server https://172.42.42.100:6443 --certificate-authority=ca.crt

# set user credentials
kubectl --kubeconfig john.kubeconfig config set-credentials john --client-certificate john.crt --client-key john.key

# set context
kubectl --kubeconfig john.kubeconfig config set-context john-kubernets --cluster kubernetes --namespace sample --user john

# set current context and check access
kubectl --kubeconfig john.kubeconfig get pods

# create Role
kubectl create role john-sample --resource=pods --verb=get,list --namespace sample
kubectl get roles -n sample

# create rolebinding - user level
kubectl create rolebinding john-sample-rolebinding --role=john-sample --user=john --namespace sample
kubectl get rolebinding -n sample

## create rolebinding - group level
#kubectl create rolebinding sample-rolebinding --role=john-sample --group=sample --namespace sample

# Access pods now 
kubectl --kubeconfig john.kubeconfig get pods

kubectl auth can-i list pods --namespace default
kubectl auth can-i list pods --namespace default --as john
kubectl get pods --as john

# csr requst yaml
kubectl create -f signing-request.yaml
kubectl get csr

# approve above csr with admin
kubectl certificate approve john-csr
kubectl get csr

# Gather the crt from the above csr and base64 decode --> john.csr
kubectl get csr john-csr -o yaml
kubectl get csr john-csr -o json

############################### Service accounts ############################################

# get the token from default secret in any namespace
kubectl get secrets default-token-zbv4l -o yaml

curl -X GET --cacert ca.crt --header "Authorization: Bearer $token" https://172.42.42.100:6443/version

kubectl get serviceaccounts
kubectl get svc

/var/run/secrets/kubernetes.io/
/tmp/secrets/kubernetes.io/serviceaccount
token, namespace, ca.cert

curl -X GET --cacert ca.crt --header "Authorization: Bearer $token" https://172.42.42.100:6443/api/v1/namespaces/default/services
 "message": "services is forbidden: User \"system:serviceaccount:default:default\" cannot list resource \"services\" in API group \"\" in the namespace \"default\""

# Giving view access to default service account
kubectl create rolebinding default-view --clusterrole=view --serviceaccount=default:default --namespace=default
curl -X GET --cacert ca.crt --header "Authorization: Bearer $token" https://172.42.42.100:6443/api/v1/namespaces/default/services


########################################### Helm #################################################
wget https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz
sudo mv helm /usr/local/bin

Service Account : tiller
Cluster Rolebinding: cluster-admin

kubectl create serviceaccount tiller -n kube-system
kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
helm init --service-account tiller


helm repo list
helm repo update


helm search jenkins
helm inspect stable/jenkins
helm fetch stable/jenkins

helm install stable/jenkins
helm status stable/jenkins
helm list
helm status trendsetting-mongoose
helm delete trendsetting-mongoose

helm upgrade
helm rollback
helm delete --purge


# To remove helm/tiller
# helm reset [--force] [--remove-helm-home]

helm install <repo>/<package> --name --values <values.yaml>

## helm2 to helm3
helm install stable/phpmyadmin --name phpmyadmin

wget https://get.helm.sh/helm-v3.0.2-linux-amd64.tar.gz
tar -xvzf helm-v3.0.2-linux-amd64.tar.gz
sudo mv linux-amd64/helm /usr/local/bin/helm

#helm3 repo add stable https://kubernetes-charts.storage.googleapis.com

helm3 plugin list
helm3 plugin install https://github.com/helm/helm-2to3
helm3 2to3 help
helm3 2to3 move config

helm3 2to3 convert phpmyadmin

# removes tiller and move the releases
helm3 2to3 cleanup

helm3 uninstall phpmyadmin
hel3 search repo phpmyadmin
helm3 install phpmyadmin stable/phpmyadmin

## Creting helm charts
helm3 install  my-nginx .
# helm2 install --name my-nginx .
helm3 upgrade my-nginx .
helm3 rollback my-nginx 1
helm3 rollback my-nginx 2

helm3 uninstall my-nginx

helm3 install my-nginx . --set replicaCount=2
helm3 upgrade my-nginx . --set replicaCount=2

helm3 inspect values .
helm3 inspect values . >/tmp/my-nginx.values

helm3 install my-nginx . --values /tmp/my-nginx.values
helm3 upgrade my-nginx . --values /tmp/my-nginx.values

# helm create directory structure
helm3 create myapp

helm3 package my-nginx -->  /home/vagrant/my-nginx-0.2.0.tgz

## local repo
helm serve --repo-path .
# helm serve --repo-path . --address "0.0.0.0:5000"
helm repo index .

helm repo update myrepo

helm repo list
helm repo add local http://127.0.0.1:8879/charts
helm repo add myrepo http://ip:5000/charts
helm search local/

helm install --name my-nginx local/my-nginx


##################################### Dynamic NFS Provisioning #########################################

# refer nfs-provisioner folder
kubectl create -f default-sc.yaml
kubectl get storageclass

kubectl create -f rbac.yaml
kubectl create -f deployment.yaml

kubectl create -f pvc-nfs1.yaml

####################################### Kube state metrics ############################################
git clone https://github.com/kubernetes/kube-state-metrics.git
cd kube-state-metrics
kubectl apply -f examples/standard

kubectl proxy

curl localhost:8001/api/v1/namespaces/kube-system/services/kube-state-metrics:http-metrics/proxy/metrics

curl http://localhost:8001/api/v1/namespaces/kube-system/services/kube-state-metrics:http-metrics/proxy/metrics | grep kube_node_status_capacity_cpu_cores

############################################ Kube API #################################################
kubectl proxy --accept-hosts=".*" --address="0.0.0.0"

/api/ (the core APIs) --> core api group
/apis/<api-group>/ (APIs grouped by API group) --> Ex: /apis/batch/v1/

Namespaced:
/api/v1/namespaces/<namespace-name>/<resource-type-name>/<resource-name>
/apis/<api-group>/<api-version>/namespaces/<namespace-name>/<resource-type-name>/<resource-name>

Non Namespaces:
/api/v1/<resource-type-name>/<resource-name>
/apis/<api-group>/<api-version>/<resource-type-name>/<resource-name>

swagger:
http://localhost:8001/openapi/v2

/proxy, /exec, /attach, /logs --> streaming requests
/api/v1/namespaces/default/pods/some-pod/logs

?watch=true


